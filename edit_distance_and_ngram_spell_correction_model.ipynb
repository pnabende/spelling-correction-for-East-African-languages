{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOtW5OCuZQH0gQJMNFNYwzH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pnabende/spelling-correction-for-East-African-languages/blob/master/edit_distance_and_ngram_spell_correction_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary packages"
      ],
      "metadata": {
        "id": "Tf5Kky0P97Oo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E28XZ5tn9yPh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.util import ngrams\n",
        "from nltk.metrics import edit_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open the Google drive folder that has the datasets"
      ],
      "metadata": {
        "id": "KDoJIs2E9-7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tnual6z-HK-",
        "outputId": "8269f1ba-055b-464e-bc5d-26803560b2bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the datasets"
      ],
      "metadata": {
        "id": "LWkYUcqF-MIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/research/spelling-correction/data/sampled-10000train-1000test/train-10000-luganda-double-tripple-errors.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/research/spelling-correction/data/sampled-10000train-1000test/test-1000-single-A-error.csv')"
      ],
      "metadata": {
        "id": "GIzeVtZq-N-5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define edit distance model"
      ],
      "metadata": {
        "id": "7PkWQVlS-U7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Edit Distance Model\n",
        "def edit_distance_correction(word, candidates):\n",
        "    return min(candidates, key=lambda candidate: edit_distance(word, candidate))\n"
      ],
      "metadata": {
        "id": "BnMM-FWI-W2R"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define ngram model"
      ],
      "metadata": {
        "id": "5q8YFkCp-bFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: N-gram Model\n",
        "def generate_ngrams(word, n):\n",
        "    return list(ngrams(word, n))\n",
        "\n",
        "def ngram_correction(word, candidates, n):\n",
        "    word_ngrams = generate_ngrams(word, n)\n",
        "    candidate_scores = {candidate: 0 for candidate in candidates}\n",
        "\n",
        "    for candidate in candidates:\n",
        "        candidate_ngrams = generate_ngrams(candidate, n)\n",
        "        common_ngrams = set(word_ngrams) & set(candidate_ngrams)\n",
        "        candidate_scores[candidate] = len(common_ngrams)\n",
        "\n",
        "    return max(candidate_scores, key=candidate_scores.get)"
      ],
      "metadata": {
        "id": "Yr5lgOUp-cqR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define training function:\n",
        "\n",
        "- Note that there is nothing to train for edit-distance\n",
        "- ngram model uses ngram frequencies in the training data"
      ],
      "metadata": {
        "id": "olarv47g-hnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_spell_correction_models(train_df):\n",
        "    # Edit Distance Model: Nothing to train, as it's rule-based\n",
        "    # N-gram Model: Count n-grams frequencies in the training data\n",
        "\n",
        "    n_gram_freq = {}\n",
        "    n_max = 4  # Maximum n-gram size\n",
        "\n",
        "    for n in range(1, n_max + 1):\n",
        "        for _, row in train_df.iterrows():\n",
        "            incorrect_word = str(row['incorrect_word'])  # Convert to string\n",
        "            correct_word = str(row['correct_word'])  # Convert to string\n",
        "            candidates = [correct_word]  # Add the correct word as a candidate\n",
        "\n",
        "            # Use character-level tokenization\n",
        "            incorrect_ngrams = generate_ngrams(incorrect_word, n)\n",
        "            correct_ngrams = generate_ngrams(correct_word, n)\n",
        "            n_grams = set(incorrect_ngrams + correct_ngrams)\n",
        "\n",
        "            for n_gram in n_grams:\n",
        "                if n_gram not in n_gram_freq:\n",
        "                    n_gram_freq[n_gram] = {'correct_word': 0, 'incorrect_word': 0}\n",
        "\n",
        "                if n_gram in correct_ngrams:\n",
        "                    n_gram_freq[n_gram]['correct_word'] += 1\n",
        "                elif n_gram in incorrect_ngrams:\n",
        "                    n_gram_freq[n_gram]['incorrect_word'] += 1\n",
        "\n",
        "    return n_gram_freq\n"
      ],
      "metadata": {
        "id": "0E7uMDM5-jK5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the models"
      ],
      "metadata": {
        "id": "ExyGpoDv-sMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the models\n",
        "def evaluate_models(test_df, edit_distance_model=False, n_gram_model=False):\n",
        "    if edit_distance_model:\n",
        "        edit_distance_correct_count = 0\n",
        "\n",
        "    if n_gram_model:\n",
        "        n_gram_freq = train_spell_correction_models(train_df)\n",
        "        n_gram_correct_count = 0\n",
        "\n",
        "    total_count = len(test_df)\n",
        "\n",
        "    for _, row in test_df.iterrows():\n",
        "        incorrect_word = row['incorrect_word']\n",
        "        correct_word = row['correct_word']\n",
        "\n",
        "        if edit_distance_model:\n",
        "            edit_distance_correction_result = edit_distance_correction(\n",
        "                incorrect_word, [correct_word])\n",
        "            if edit_distance_correction_result == correct_word:\n",
        "                edit_distance_correct_count += 1\n",
        "\n",
        "        if n_gram_model:\n",
        "            max_n = 4  # Maximum n-gram size to check\n",
        "            n_gram_candidates = set()\n",
        "\n",
        "            for n in range(1, max_n + 1):\n",
        "                n_gram_candidates.add(ngram_correction(\n",
        "                    incorrect_word, [correct_word], n))\n",
        "\n",
        "            if correct_word in n_gram_candidates:\n",
        "                n_gram_correct_count += 1\n",
        "\n",
        "    if edit_distance_model:\n",
        "        edit_distance_accuracy = edit_distance_correct_count / total_count\n",
        "        print(f\"Edit Distance Model Accuracy: {edit_distance_accuracy:.2%}\")\n",
        "\n",
        "    if n_gram_model:\n",
        "        n_gram_accuracy = n_gram_correct_count / total_count\n",
        "        print(f\"N-gram Model Accuracy: {n_gram_accuracy:.2%}\")"
      ],
      "metadata": {
        "id": "-aQenOXl-qC3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the models"
      ],
      "metadata": {
        "id": "BHRYkQbY_Hzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_gram_freq = train_spell_correction_models(train_df)"
      ],
      "metadata": {
        "id": "KoKgjfHr_JYc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the models"
      ],
      "metadata": {
        "id": "ie91GgD3_NKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_models(test_df, edit_distance_model=True, n_gram_model=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq1j4cvv_PUx",
        "outputId": "2b66ff29-0fa9-4071-b2c8-8b31cdc6e668"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edit Distance Model Accuracy: 100.00%\n",
            "N-gram Model Accuracy: 100.00%\n"
          ]
        }
      ]
    }
  ]
}